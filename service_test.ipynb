{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#import sys\n",
    "#print(sys.version)\n",
    "#import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import expo_nrml as nrml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_point_list = [-33.2,-33.0 , -33.0, -33.2, -33.2]\n",
    "lon_point_list = [-71.8, -71.8,-71.4,-71.4,-71.8]\n",
    "\n",
    "roi_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "crs = {'init': 'epsg:4326'}\n",
    "roi = gp.GeoDataFrame(index=[0], crs=crs, geometry=[roi_geom])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON ((-71.8 -33.2, -71.8 -33, -71.40000000000001 -33, -71.40000000000001 -33.2, -71.8 -33.2))'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_geom.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init model from file (geopackage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {\"type\": \"FeatureCollection\", \"features\": [{\"i...\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rj = roi.to_json()\n",
    "#rj\n",
    "gs = gp.GeoSeries(rj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "read exposure model from a (geopackage) file, filter and harmonise \n",
    "the columns in order to have for each geocell the following:\n",
    "index: integer unique identifier\n",
    "gc_id: string, unique identifier\n",
    "name: string, name\n",
    "geometry: polygon\n",
    "a number of columns follow, each describing a single taxonomic type\n",
    "\n",
    "returns the model as geopandas dataframe and the list of taxonomic types\n",
    "'''\n",
    "def read_model(input_file):\n",
    "    #init model\n",
    "    res = gp.read_file(input_file,encoding = 'utf-8')\n",
    "    taxonomies = res.keys()[res.dtypes=='float64']\n",
    "    cols = ['GID_3','NAME_3','geometry',*taxonomies.values]\n",
    "    out = res[cols].reset_index()\n",
    "    out.columns = ['index','gc_id','name','geometry',*taxonomies.values]\n",
    "    return [out,taxonomies]\n",
    "\n",
    "'''\n",
    "extract a part of the model by doing a spatial query on the geopandas df\n",
    "return a sub-portion of a model based on a ROI and a query mode: \n",
    "'within': returns the geometries that are completely inside the ROI\n",
    "'intersects': returns the geometries that are intersecting the ROI\n",
    "'''\n",
    "def queryModelfromRoi(mod,roi,mode='within'):\n",
    "    #modes=['within','intersects']\n",
    "    r = roi.geometry.iloc[0]\n",
    "    if (mode=='within'):\n",
    "        res=mod[mod.within(r)]\n",
    "    elif(mode=='intersects'):\n",
    "        res=mod[mod.intersects(r)]\n",
    "    else:\n",
    "        raise Exception ('getModelfromRoi: unknown mode')\n",
    "    return(res)\n",
    "\n",
    "'''\n",
    "Export geopandas dataframe as GeoJson file\n",
    "'''\n",
    "def exportGeoJson(dataframe, filename):\n",
    "    # file has to be first deleted\n",
    "    # because driver does not support overwrite ! \n",
    "    try: \n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "    dataframe.to_file(filename, driver='GeoJSON')\n",
    "    return (0)\n",
    "\n",
    "def exportNrml05(dataframe, filename, metadata, dicts,taxonomies):\n",
    "    xml_string = nrml.write_nrml05_expo(dataframe,metadata,dicts,taxonomies,filename)\n",
    "    return (0)\n",
    "\n",
    "#test\n",
    "#sub = getModelfromRoi(model,roi,'intersects')\n",
    "#print(sub)\n",
    "#sub.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'SARA_v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(roi,schema):\n",
    "    \n",
    "    #init file path and file names according to specific schema.\n",
    "    #currently only the SARA v1.0 schema is supported\n",
    "\n",
    "    if (schema == 'SARA_v1.0'):\n",
    "        path_expo_dict =\"/Users/pittore/Documents/workspace/RIESGOS/assetmaster/model_SARA_v1.0\"\n",
    "        path_metadatefile = \"/Users/pittore/Documents/workspace/RIESGOS/assetmaster/model_SARA_v1.0\"\n",
    "        path_infile = \"/Users/pittore/Documents/workspace/RIESGOS/assetmaster/model_SARA_v1.0\"\n",
    "        path_outfile = \"/Users/pittore/Documents/workspace/RIESGOS/assetmaster/output\"\n",
    "    else:\n",
    "        raise Exception (\"schema {} not supported\".format(schema))\n",
    "\n",
    "    in_file = \"chile_sara_v1.0_data.gpkg\"\n",
    "    dict_file = \"chile_sara_v1.0_prop.csv\"\n",
    "    metadata_file = \"chile_sara_v1.0_meta.json\"\n",
    "    out_file_xml = \"query_output.nrml\"\n",
    "    out_file_geojson = 'query_output.geojson'\n",
    "\n",
    "    #read the exposure model metadata\n",
    "    metadata = nrml.read_metadata(os.path.join(path_metadatefile,metadata_file))\n",
    "\n",
    "    #get a dataframe with the basic properties of the buildings\n",
    "    dicts = nrml.load_expo_dicts(os.path.join(path_expo_dict,dict_file))\n",
    "\n",
    "    #read taxonomies from the dict file\n",
    "    btypes = dicts.btype\n",
    "    #check that the asset taxonomies match\n",
    "    if not (set(taxonomies) <= set(btypes)):\n",
    "        raise Exception (\"taxonomies do not match\")\n",
    "\n",
    "    #read model from file \n",
    "    model,taxonomies = read_model(os.path.join(path_infile,in_file))\n",
    "\n",
    "    #spatial query\n",
    "    query_res = queryModelfromRoi(model,roi,'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_geojson = os.path.join(path_outfile,out_file_geojson)\n",
    "exportGeoJson(query_res,output_geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_xml = os.path.join(path_outfile,out_file_xml)\n",
    "exportNrml05(query_res, output_xml, metadata, dicts,taxonomies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_res = queryModelfromRoi(model,roi,'intersects')\n",
    "query_res.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "m = folium.Map([-33.08,-71.6], zoom_start=8, tiles='cartodbpositron')\n",
    "folium.GeoJson(polygon).add_to(m)\n",
    "folium.GeoJson(res.boundary,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#00FF00',\n",
    "        'color' : '#32CD32',\n",
    "        'weight' : 1,\n",
    "        'fillOpacity' : 0.5,\n",
    "        }).add_to(m)\n",
    "folium.LatLngPopup().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env/python\n",
    "\n",
    "'''\n",
    "Assetmaster\n",
    "-----------------\n",
    "Command line program to query exposure data from a database/file.\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import expo_nrml as nrml\n",
    "\n",
    "class Main():\n",
    "    '''\n",
    "    Main class to execute\n",
    "    '''\n",
    "    def __init__(self, args):\n",
    "        self.folder = os.path.dirname(__file__)\n",
    "\n",
    "        # command line arguments\n",
    "        self.lonmin = args.lonmin\n",
    "        self.lonmax = args.lonmax\n",
    "        self.latmin = args.latmin\n",
    "        self.latmax = args.latmax\n",
    "        self.schema = args.schema\n",
    "        self.assettype = args.assettype\n",
    "        \n",
    "        #i/o settings\n",
    "        self.path_expo_dict = self.folder\n",
    "        self.path_metadatefile = self.folder\n",
    "        self.path_infile = self.folder\n",
    "        self.in_file = self.folder\n",
    "        self.dict_file = self.folder\n",
    "        self.metadata_file = self.folder\n",
    "        self.path_outfile = os.path.join(self.folder,\"output\")\n",
    "        self.out_file_xml = \"query_output.nrml\"\n",
    "        self.out_file_geojson = 'query_output.geojson'\n",
    "        \n",
    "        self.roi = None\n",
    "        self.metadata = None\n",
    "        self.dicts = None \n",
    "        self.taxonomies = None\n",
    "\n",
    "        #list of supported schemas. \n",
    "        #TODO: automatically parse them from a given folder\n",
    "        self.supported_schemas = ['SARA_v1.0']\n",
    "\n",
    "        # in case there is some deaggregation necessary\n",
    "        # precision\n",
    "        self.precision_lon = 0\n",
    "        self.precision_lat = 0\n",
    "\n",
    "        # result\n",
    "        self.query_result = None\n",
    "\n",
    "    def _compute_roi(self):\n",
    "        lat_point_list = [self.latmin,self.latmax ,self.latmax, self.latmin,self.latmin]\n",
    "        lon_point_list = [self.lonmin, self.lonmin,self.lonmax,self.lonmax,self.lonmin]\n",
    "        roi_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "        crs = {'init': 'epsg:4326'}\n",
    "        self.roi = gp.GeoDataFrame(index=[0], crs=crs, geometry=[roi_geom])       \n",
    "\n",
    "    def _check_schema(self):\n",
    "        return(set([self.schema]) <= set(self.supported_schemas))\n",
    "\n",
    "    def _check_longitude(self):\n",
    "        '''If there is a longitude > 180 than it should be converted'''\n",
    "        if self.lonmin > 180:\n",
    "            self.lonmin = Main._convert_360(self.lonmin)\n",
    "        if self.lonmax > 180:\n",
    "            self.lonmax = Main._convert_360(self.lonmax)\n",
    "            \n",
    "    @staticmethod\n",
    "    def _convert_360(lon):\n",
    "        '''\n",
    "        convert a longitude specified with 180+\n",
    "        '''\n",
    "        return lon-360\n",
    "    \n",
    "        \n",
    "    def read_model(self,input_file):\n",
    "        '''\n",
    "        read exposure model from a (geopackage) file, filter and harmonise \n",
    "        the columns in order to have for each geocell the following:\n",
    "        index: integer unique identifier\n",
    "        gc_id: string, unique identifier\n",
    "        name: string, name\n",
    "        geometry: polygon\n",
    "        a number of columns follow, each describing a single taxonomic type\n",
    "\n",
    "        returns the model as geopandas dataframe and the list of taxonomic types\n",
    "        '''\n",
    "        #init model\n",
    "        #input_file = 'schemas/SARA_v1.0/SARA_v1.0_data.gpkg'\n",
    "        res = gp.read_file(input_file,encoding = 'utf-8')\n",
    "        taxonomies = res.keys()[res.dtypes=='float64']\n",
    "        cols = ['GID_3','NAME_3','geometry',*taxonomies.values]\n",
    "        out = res[cols].reset_index()\n",
    "        out.columns = ['index','gc_id','name','geometry',*taxonomies.values]\n",
    "        return [out,taxonomies]\n",
    "    \n",
    "    def queryModelfromRoi(self,mod,roi,mode='within'):\n",
    "        '''\n",
    "        extract a part of the model by doing a spatial query on the geopandas df\n",
    "        return a sub-portion of a model based on a ROI and a query mode: \n",
    "        'within': returns the geometries that are completely inside the ROI\n",
    "        'intersects': returns the geometries that are intersecting the ROI\n",
    "        '''\n",
    "        #modes=['within','intersects']\n",
    "        r = roi.geometry.iloc[0]\n",
    "        if (mode=='within'):\n",
    "            res=mod[mod.within(r)]\n",
    "        elif(mode=='intersects'):\n",
    "            res=mod[mod.intersects(r)]\n",
    "        else:\n",
    "            raise Exception ('getModelfromRoi: unknown mode')\n",
    "        return(res)\n",
    "    \n",
    "    def _exportGeoJson(self, dataframe, filename):\n",
    "        '''\n",
    "        Export geopandas dataframe as GeoJson file\n",
    "        '''\n",
    "        # file has to be first deleted\n",
    "        # because driver does not support overwrite ! \n",
    "        try: \n",
    "            os.remove(filename)\n",
    "        except OSError:\n",
    "            pass\n",
    "        dataframe.to_file(filename, driver='GeoJSON')\n",
    "        return (0)\n",
    "\n",
    "    def _exportNrml05(self, dataframe, filename, metadata, dicts,taxonomies):\n",
    "        '''\n",
    "        Export geopandas dataframe as nrml file\n",
    "        '''\n",
    "        xml_string = nrml.write_nrml05_expo(dataframe,metadata,dicts,taxonomies,filename)\n",
    "        return (0)\n",
    "\n",
    "    def _write_outputs(self):\n",
    "        '''\n",
    "        Export query result as nrml and geojson files\n",
    "        '''\n",
    "        output_geojson = os.path.join(self.path_outfile,self.out_file_geojson)\n",
    "        self._exportGeoJson(self.query_result,output_geojson)\n",
    "        output_xml = os.path.join(self.path_outfile,self.out_file_xml)\n",
    "        self._exportNrml05(self.query_result, output_xml, self.metadata, \n",
    "                           self.dicts,self.taxonomies)\n",
    "    \n",
    "    def run(self):\n",
    "        '''\n",
    "        Method to:\n",
    "        - connect with the database\n",
    "        - query the database\n",
    "        - do some deaggregation if necessary\n",
    "        - write the output\n",
    "        '''\n",
    "\n",
    "        self._check_longitude()\n",
    "        self._compute_roi()\n",
    "        \n",
    "        if (self._check_schema()):\n",
    "            foldername = os.path.join(self.folder,\"schemas/{}\".format(self.schema))\n",
    "            self.path_expo_dict = foldername\n",
    "            self.path_metadatefile = foldername\n",
    "            self.path_infile = foldername\n",
    "            self.in_file = \"{}_data.gpkg\".format(self.schema)\n",
    "            self.dict_file = \"{}_prop.csv\".format(self.schema)\n",
    "            self.metadata_file = \"{}_meta.json\".format(self.schema)\n",
    "        else:\n",
    "            raise Exception (\"schema {} not supported\".format(self.schema))\n",
    "\n",
    "        #read the exposure model metadata\n",
    "        self.metadata = nrml.read_metadata(os.path.join(self.path_metadatefile,self.metadata_file))\n",
    "\n",
    "        #read model from file \n",
    "        in_file = os.path.join(self.path_infile,self.in_file)\n",
    "        \n",
    "        self.model,self.taxonomies = self.read_model(in_file)#'schemas/SARA_v1.0/SARA_v1.0_data.gpkg')\n",
    "\n",
    "        #print(self.taxonomies)\n",
    "        #get a dataframe with the basic properties of the buildings\n",
    "        self.dicts = nrml.load_expo_dicts(os.path.join(self.path_expo_dict,self.dict_file))\n",
    "\n",
    "        #read taxonomies from the dict file\n",
    "        btypes = self.dicts.btype\n",
    "\n",
    "        #check that the asset taxonomies match\n",
    "        if not (set(self.taxonomies) <= set(btypes)):\n",
    "            raise Exception (\"taxonomies do not match\")\n",
    "\n",
    "        #spatial query\n",
    "        print (self.roi)\n",
    "        self.query_result = self.queryModelfromRoi(self.model,self.roi,'intersects')\n",
    "\n",
    "        self._write_outputs()\n",
    "        return (0)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def create_with_arg_parser(cls):\n",
    "        '''\n",
    "        Creates an arg parser and uses that to create the Main class\n",
    "        '''\n",
    "        arg_parser = argparse.ArgumentParser(\n",
    "            description='''Program to query an exposure model from a database/file'''\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            'lonmin',\n",
    "            help='Region Of Interest: Minimal longitude',\n",
    "            type=float,\n",
    "            default=-71.8)\n",
    "        arg_parser.add_argument(\n",
    "            'lonmax',\n",
    "            help='Region Of Interest: Maximal longitude',\n",
    "            type=float,\n",
    "            default=-71.4)\n",
    "        arg_parser.add_argument(\n",
    "            'latmin',\n",
    "            help='Region Of Interest: Minimal latitude',\n",
    "            type=float,\n",
    "            default=-33.2)\n",
    "        arg_parser.add_argument(\n",
    "            'latmax',\n",
    "            help='Region Of Interest: Maximal latitude',\n",
    "            type=float,\n",
    "            default=-33.0)\n",
    "        arg_parser.add_argument(\n",
    "            'schema',\n",
    "            help='Exposure/Vulnerability Schema',\n",
    "            type=str,\n",
    "            default=\"SARA_v1.0\")\n",
    "        arg_parser.add_argument(\n",
    "            'assettype',\n",
    "            help='Type of exposed assets',\n",
    "            type=str,\n",
    "            default='res')\n",
    "        args = arg_parser.parse_args()\n",
    "\n",
    "        return cls(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Main.create_with_arg_parser().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-155-3b5053ae029f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-155-3b5053ae029f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    {assettype='res', latmax=-33.0, latmin=-33.2, lonmax=-71.4, lonmin=-71.8, schema='SARA_v1.0'}\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{assettype='res', latmax=-33.0, latmin=-33.2, lonmax=-71.4, lonmin=-71.8, schema='SARA_v1.0'}\n",
    "#Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
